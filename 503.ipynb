{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from torch) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pulearn\n",
      "  Using cached pulearn-0.0.11-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy~=1.26.4 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from pulearn) (1.26.4)\n",
      "Collecting scikit-learn<1.6,>=1.4.2 (from pulearn)\n",
      "  Using cached scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six~=1.16.0 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from pulearn) (1.16.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from scikit-learn<1.6,>=1.4.2->pulearn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from scikit-learn<1.6,>=1.4.2->pulearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\tree-failure-analysis\\.venv\\lib\\site-packages (from scikit-learn<1.6,>=1.4.2->pulearn) (3.5.0)\n",
      "Using cached pulearn-0.0.11-py3-none-any.whl (18 kB)\n",
      "Using cached scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Installing collected packages: scikit-learn, pulearn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "Successfully installed pulearn-0.0.11 scikit-learn-1.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~_check_build'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\eoinm\\AppData\\Local\\Temp\\pip-uninstall-_2wynw_j'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~loss'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~luster'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~atasets'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~ecomposition'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~eature_extraction'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~anifold'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~etrics'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~eighbors'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~reprocessing'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~vm'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Tree-Failure-Analysis\\.venv\\Lib\\site-packages\\sklearn\\~ree'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install torch\n",
    "%pip install numpy\n",
    "%pip install sklearn\n",
    "%pip install scikit-learn\n",
    "%pip install pulearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.optim as optim\n",
    "# import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "# from torch.utils.data.dataset import random_split\n",
    "# import torch.nn.functional as F\n",
    "# from pulearn import ElkanotoPuClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "# from pulearn import BaggingPuClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       2\n",
      "2       3\n",
      "3       3\n",
      "4       4\n",
      "       ..\n",
      "498    45\n",
      "499     1\n",
      "500    45\n",
      "501     3\n",
      "502    75\n",
      "Name: Tree Species, Length: 503, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dat = pd.read_csv(\"PNWTFDB_2018_0_503points.csv\")\n",
    "\n",
    "dropped = [\n",
    "    \"GlobalID\",\n",
    "    \"Date of Failure\",\n",
    "    \"Other\",\n",
    "    \"CreationDate\",\n",
    "    \"Creator\",\n",
    "    \"EditDate\",\n",
    "    \"Editor\",\n",
    "    \"Care Factors\",\n",
    "    \"x\",\n",
    "    \"y\"\n",
    "]\n",
    "dat = dat.drop(columns=dropped, axis=1)\n",
    "\n",
    "fill_none = [\n",
    "    \"Site Factors\",\n",
    "    \"Root Failure\",\n",
    "    \"Stem Failure\",\n",
    "    \"Branch Failure\",\n",
    "    \"Location and Percentage of Decay\",\n",
    "    \"Weather factors\",\n",
    "    \"Decay Present\"\n",
    "]\n",
    "\n",
    "dat[\"Type of Soil\"] = dat[\"Type of Soil\"].fillna(value=\"Dirt\")\n",
    "dat.loc[:, fill_none] = dat[fill_none].fillna(\"None\")\n",
    "\n",
    "dat['Length of Failed Part'] = dat.groupby(['Failed Part', 'Tree Species'])['Length of Failed Part'].transform( lambda x: x.fillna(x.mean()))\n",
    "dat['Length of Failed Part'] = dat.groupby(['Failed Part'])['Length of Failed Part'].transform( lambda x: x.fillna(x.mean()))\n",
    "dat.to_csv('treedata.csv', index=False)\n",
    "\n",
    "#print(dat[\"Length of Failed Part\"])\n",
    "\n",
    "def tree_mapping(df, name):\n",
    "    t_map = {name: i for i, name in enumerate(df[name].unique(), start=1)}\n",
    "    df[name] = df[name].map(t_map)\n",
    "\n",
    "tree_mapping(dat, 'Tree Species')\n",
    "tree_mapping(dat, 'Condition')\n",
    "tree_mapping(dat, 'Site Factors')\n",
    "tree_mapping(dat, 'Type of Soil')\n",
    "tree_mapping(dat, 'Weather factors')\n",
    "tree_mapping(dat, 'Failed Part')\n",
    "tree_mapping(dat, 'Root Failure')\n",
    "tree_mapping(dat, 'Branch Failure')\n",
    "tree_mapping(dat, 'Stem Failure')\n",
    "tree_mapping(dat, 'Location and Percentage of Decay')\n",
    "tree_mapping(dat, 'Decay Present')\n",
    "print(dat['Tree Species'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Estimator: SVC(C=10, gamma=0.4, probability=True, random_state=42)\n",
       "p(s=1|y=1,x) ~= 0.7946217321795251\n",
       "Fitted: True</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ElkanotoPuClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Estimator: SVC(C=10, gamma=0.4, probability=True, random_state=42)\n",
       "p(s=1|y=1,x) ~= 0.7946217321795251\n",
       "Fitted: True</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: SVC</label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=10, gamma=0.4, probability=True, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=10, gamma=0.4, probability=True, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElkanotoPuClassifier(estimator=SVC(C=10, gamma=0.4, probability=True,\n",
       "                                   random_state=42),\n",
       "                     hold_out_ratio=0.2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(C=10, kernel='rbf', gamma=0.4, probability=True, random_state=42)\n",
    "\n",
    "pu_estimator = ElkanotoPuClassifier(estimator=svc, hold_out_ratio=0.2)\n",
    "\n",
    "y = np.concatenate([np.ones(400), np.zeros(103)])\n",
    "#np.random.shuffle(y)\n",
    "X = dat.values\n",
    "\n",
    "#X, y = X[:len(y)], y\n",
    "\n",
    "pu_estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "(503,)\n",
      "\n",
      "Comparison of estimator and PUAdapter(estimator):\n",
      "Number of disagreements: 82\n",
      "Number of agreements: 421\n"
     ]
    }
   ],
   "source": [
    "print(pu_estimator.predict(X))\n",
    "print(pu_estimator.predict(X).shape)\n",
    "print(\"\\nComparison of estimator and PUAdapter(estimator):\")\n",
    "print(\n",
    "    \"Number of disagreements: {}\".format(\n",
    "        len(np.where(pu_estimator.predict(X) != np.ones(503))[0])\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Number of agreements: {}\".format(\n",
    "        len(np.where(pu_estimator.predict(X) == np.ones(503))[0])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11845446 0.88154554]\n",
      " [0.11845972 0.88154028]\n",
      " [0.11845915 0.88154085]\n",
      " [0.1184646  0.8815354 ]\n",
      " [0.11846441 0.88153559]\n",
      " [0.11846277 0.88153723]\n",
      " [0.1184629  0.8815371 ]\n",
      " [0.11846722 0.88153278]\n",
      " [0.11846522 0.88153478]\n",
      " [0.11846537 0.88153463]\n",
      " [0.11846582 0.88153418]\n",
      " [0.11847065 0.88152935]\n",
      " [0.11846989 0.88153011]\n",
      " [0.11845657 0.88154343]\n",
      " [0.11846176 0.88153824]\n",
      " [0.11845678 0.88154322]\n",
      " [0.11846356 0.88153644]\n",
      " [0.11846357 0.88153643]\n",
      " [0.11844785 0.88155215]\n",
      " [0.11845011 0.88154989]\n",
      " [0.11846124 0.88153876]\n",
      " [0.11846957 0.88153043]\n",
      " [0.11847068 0.88152932]\n",
      " [0.11848061 0.88151939]\n",
      " [0.11847931 0.88152069]\n",
      " [0.11847195 0.88152805]\n",
      " [0.11847944 0.88152056]\n",
      " [0.11849802 0.88150198]\n",
      " [0.11850154 0.88149846]\n",
      " [0.1184814  0.8815186 ]\n",
      " [0.11848301 0.88151699]\n",
      " [0.11850729 0.88149271]\n",
      " [0.11847254 0.88152746]\n",
      " [0.11848758 0.88151242]\n",
      " [0.11847714 0.88152286]\n",
      " [0.11847147 0.88152853]\n",
      " [0.11848098 0.88151902]\n",
      " [0.11847562 0.88152438]\n",
      " [0.118477   0.881523  ]\n",
      " [0.11847793 0.88152207]\n",
      " [0.11845893 0.88154107]\n",
      " [0.11848476 0.88151524]\n",
      " [0.11849318 0.88150682]\n",
      " [0.11849075 0.88150925]\n",
      " [0.1184831  0.8815169 ]\n",
      " [0.11848889 0.88151111]\n",
      " [0.11848411 0.88151589]\n",
      " [0.11846944 0.88153056]\n",
      " [0.11847183 0.88152817]\n",
      " [0.11846754 0.88153246]\n",
      " [0.11846137 0.88153863]\n",
      " [0.11846123 0.88153877]\n",
      " [0.11846797 0.88153203]\n",
      " [0.11846194 0.88153806]\n",
      " [0.11846223 0.88153777]\n",
      " [0.1184568  0.8815432 ]\n",
      " [0.11845464 0.88154536]\n",
      " [0.11846701 0.88153299]\n",
      " [0.11846805 0.88153195]\n",
      " [0.11846167 0.88153833]\n",
      " [0.11847055 0.88152945]\n",
      " [0.11846998 0.88153002]\n",
      " [0.11847689 0.88152311]\n",
      " [0.11847422 0.88152578]\n",
      " [0.11848044 0.88151956]\n",
      " [0.11847802 0.88152198]\n",
      " [0.11848855 0.88151145]\n",
      " [0.11849151 0.88150849]\n",
      " [0.11848555 0.88151445]\n",
      " [0.11849056 0.88150944]\n",
      " [0.11847457 0.88152543]\n",
      " [0.11847134 0.88152866]\n",
      " [0.11846912 0.88153088]\n",
      " [0.11847622 0.88152378]\n",
      " [0.11846868 0.88153132]\n",
      " [0.118473   0.881527  ]\n",
      " [0.118476   0.881524  ]\n",
      " [0.11846273 0.88153727]\n",
      " [0.11845736 0.88154264]\n",
      " [0.11846373 0.88153627]\n",
      " [0.11846944 0.88153056]\n",
      " [0.11846847 0.88153153]\n",
      " [0.11846873 0.88153127]\n",
      " [0.11846133 0.88153867]\n",
      " [0.11846114 0.88153886]\n",
      " [0.11846406 0.88153594]\n",
      " [0.11845346 0.88154654]\n",
      " [0.11845739 0.88154261]\n",
      " [0.11845329 0.88154671]\n",
      " [0.11845958 0.88154042]\n",
      " [0.11845914 0.88154086]\n",
      " [0.11848619 0.88151381]\n",
      " [0.11848008 0.88151992]\n",
      " [0.1184467  0.8815533 ]\n",
      " [0.11846488 0.88153512]\n",
      " [0.11846437 0.88153563]\n",
      " [0.11848324 0.88151676]\n",
      " [0.11848201 0.88151799]\n",
      " [0.1184816  0.8815184 ]\n",
      " [0.11848021 0.88151979]\n",
      " [0.11848704 0.88151296]\n",
      " [0.11848529 0.88151471]\n",
      " [0.11848449 0.88151551]\n",
      " [0.11848708 0.88151292]\n",
      " [0.11848673 0.88151327]\n",
      " [0.11847768 0.88152232]\n",
      " [0.11845894 0.88154106]\n",
      " [0.11846101 0.88153899]\n",
      " [0.11846027 0.88153973]\n",
      " [0.11844697 0.88155303]\n",
      " [0.11843549 0.88156451]\n",
      " [0.1184372  0.8815628 ]\n",
      " [0.11843863 0.88156137]\n",
      " [0.11845744 0.88154256]\n",
      " [0.1184402  0.8815598 ]\n",
      " [0.11845864 0.88154136]\n",
      " [0.11843768 0.88156232]\n",
      " [0.11844102 0.88155898]\n",
      " [0.11847342 0.88152658]\n",
      " [0.11847059 0.88152941]\n",
      " [0.11847787 0.88152213]\n",
      " [0.11847739 0.88152261]\n",
      " [0.11847357 0.88152643]\n",
      " [0.11848369 0.88151631]\n",
      " [0.11848998 0.88151002]\n",
      " [0.11848241 0.88151759]\n",
      " [0.11847258 0.88152742]\n",
      " [0.11847764 0.88152236]\n",
      " [0.11848347 0.88151653]\n",
      " [0.11848767 0.88151233]\n",
      " [0.11848515 0.88151485]\n",
      " [0.11847551 0.88152449]\n",
      " [0.11846854 0.88153146]\n",
      " [0.11846308 0.88153692]\n",
      " [0.11846515 0.88153485]\n",
      " [0.11846732 0.88153268]\n",
      " [0.11846776 0.88153224]\n",
      " [0.11846873 0.88153127]\n",
      " [0.11846949 0.88153051]\n",
      " [0.118472   0.881528  ]\n",
      " [0.11846667 0.88153333]\n",
      " [0.1184553  0.8815447 ]\n",
      " [0.11845862 0.88154138]\n",
      " [0.11846119 0.88153881]\n",
      " [0.11846631 0.88153369]\n",
      " [0.11845861 0.88154139]\n",
      " [0.11846434 0.88153566]\n",
      " [0.11847055 0.88152945]\n",
      " [0.11846778 0.88153222]\n",
      " [0.11845277 0.88154723]\n",
      " [0.11845216 0.88154784]\n",
      " [0.11846302 0.88153698]\n",
      " [0.11845667 0.88154333]\n",
      " [0.11846527 0.88153473]\n",
      " [0.11845957 0.88154043]\n",
      " [0.1184595  0.8815405 ]\n",
      " [0.11845314 0.88154686]\n",
      " [0.11845003 0.88154997]\n",
      " [0.11845075 0.88154925]\n",
      " [0.11844288 0.88155712]\n",
      " [0.11843824 0.88156176]\n",
      " [0.11843758 0.88156242]\n",
      " [0.11843781 0.88156219]\n",
      " [0.1184376  0.8815624 ]\n",
      " [0.11843535 0.88156465]\n",
      " [0.118459   0.881541  ]\n",
      " [0.11846215 0.88153785]\n",
      " [0.11846679 0.88153321]\n",
      " [0.1184369  0.8815631 ]\n",
      " [0.11845436 0.88154564]\n",
      " [0.11845714 0.88154286]\n",
      " [0.11845425 0.88154575]\n",
      " [0.118451   0.881549  ]\n",
      " [0.11844587 0.88155413]\n",
      " [0.11847014 0.88152986]\n",
      " [0.11848296 0.88151704]\n",
      " [0.11844113 0.88155887]\n",
      " [0.11844736 0.88155264]\n",
      " [0.11844488 0.88155512]\n",
      " [0.11845224 0.88154776]\n",
      " [0.11845842 0.88154158]\n",
      " [0.11845829 0.88154171]\n",
      " [0.1184587  0.8815413 ]\n",
      " [0.11845737 0.88154263]\n",
      " [0.11845581 0.88154419]\n",
      " [0.11847197 0.88152803]\n",
      " [0.1184725  0.8815275 ]\n",
      " [0.11845263 0.88154737]\n",
      " [0.11847042 0.88152958]\n",
      " [0.11847952 0.88152048]\n",
      " [0.11847171 0.88152829]\n",
      " [0.11847979 0.88152021]\n",
      " [0.11845176 0.88154824]\n",
      " [0.11844571 0.88155429]\n",
      " [0.11845039 0.88154961]\n",
      " [0.11844991 0.88155009]\n",
      " [0.11845271 0.88154729]\n",
      " [0.11846295 0.88153705]\n",
      " [0.11846839 0.88153161]\n",
      " [0.11847036 0.88152964]\n",
      " [0.11846756 0.88153244]\n",
      " [0.11847248 0.88152752]\n",
      " [0.11846741 0.88153259]\n",
      " [0.11847352 0.88152648]\n",
      " [0.11847769 0.88152231]\n",
      " [0.11847823 0.88152177]\n",
      " [0.11846164 0.88153836]\n",
      " [0.11847482 0.88152518]\n",
      " [0.11847255 0.88152745]\n",
      " [0.11843905 0.88156095]\n",
      " [0.11844227 0.88155773]\n",
      " [0.11844206 0.88155794]\n",
      " [0.11843709 0.88156291]\n",
      " [0.11843347 0.88156653]\n",
      " [0.11842621 0.88157379]\n",
      " [0.11843034 0.88156966]\n",
      " [0.11844143 0.88155857]\n",
      " [0.11843892 0.88156108]\n",
      " [0.11844625 0.88155375]\n",
      " [0.11843788 0.88156212]\n",
      " [0.11846019 0.88153981]\n",
      " [0.11847131 0.88152869]\n",
      " [0.11845731 0.88154269]\n",
      " [0.11846849 0.88153151]\n",
      " [0.11846887 0.88153113]\n",
      " [0.11849195 0.88150805]\n",
      " [0.1184876  0.8815124 ]\n",
      " [0.11848045 0.88151955]\n",
      " [0.11845683 0.88154317]\n",
      " [0.11846621 0.88153379]\n",
      " [0.11848149 0.88151851]\n",
      " [0.11848978 0.88151022]\n",
      " [0.11849063 0.88150937]\n",
      " [0.11848603 0.88151397]\n",
      " [0.11848207 0.88151793]\n",
      " [0.1184667  0.8815333 ]\n",
      " [0.11848387 0.88151613]\n",
      " [0.11846942 0.88153058]\n",
      " [0.1184775  0.8815225 ]\n",
      " [0.11844772 0.88155228]\n",
      " [0.11850061 0.88149939]\n",
      " [0.11847594 0.88152406]\n",
      " [0.11845762 0.88154238]\n",
      " [0.11848015 0.88151985]\n",
      " [0.11848461 0.88151539]\n",
      " [0.11846351 0.88153649]\n",
      " [0.11847546 0.88152454]\n",
      " [0.1184817  0.8815183 ]\n",
      " [0.11846733 0.88153267]\n",
      " [0.11848586 0.88151414]\n",
      " [0.11849771 0.88150229]\n",
      " [0.11849485 0.88150515]\n",
      " [0.11849532 0.88150468]\n",
      " [0.11843382 0.88156618]\n",
      " [0.11851734 0.88148266]\n",
      " [0.11843713 0.88156287]\n",
      " [0.11848941 0.88151059]\n",
      " [0.11847018 0.88152982]\n",
      " [0.11846425 0.88153575]\n",
      " [0.11846232 0.88153768]\n",
      " [0.11845409 0.88154591]\n",
      " [0.11844716 0.88155284]\n",
      " [0.11844381 0.88155619]\n",
      " [0.11845104 0.88154896]\n",
      " [0.11845078 0.88154922]\n",
      " [0.118447   0.881553  ]\n",
      " [0.11847157 0.88152843]\n",
      " [0.11847225 0.88152775]\n",
      " [0.11848209 0.88151791]\n",
      " [0.11848035 0.88151965]\n",
      " [0.1184811  0.8815189 ]\n",
      " [0.11846963 0.88153037]\n",
      " [0.1184987  0.8815013 ]\n",
      " [0.11850477 0.88149523]\n",
      " [0.11848122 0.88151878]\n",
      " [0.11846708 0.88153292]\n",
      " [0.11847524 0.88152476]\n",
      " [0.11847027 0.88152973]\n",
      " [0.11849677 0.88150323]\n",
      " [0.11849265 0.88150735]\n",
      " [0.11848283 0.88151717]\n",
      " [0.11847909 0.88152091]\n",
      " [0.11846121 0.88153879]\n",
      " [0.11844607 0.88155393]\n",
      " [0.11847692 0.88152308]\n",
      " [0.11847293 0.88152707]\n",
      " [0.11847996 0.88152004]\n",
      " [0.11848916 0.88151084]\n",
      " [0.11850041 0.88149959]\n",
      " [0.11851318 0.88148682]\n",
      " [0.118533   0.881467  ]\n",
      " [0.1185114  0.8814886 ]\n",
      " [0.11851822 0.88148178]\n",
      " [0.11850737 0.88149263]\n",
      " [0.11850385 0.88149615]\n",
      " [0.11843699 0.88156301]\n",
      " [0.1184569  0.8815431 ]\n",
      " [0.11846556 0.88153444]\n",
      " [0.1184534  0.8815466 ]\n",
      " [0.11849676 0.88150324]\n",
      " [0.11844499 0.88155501]\n",
      " [0.11843633 0.88156367]\n",
      " [0.11844081 0.88155919]\n",
      " [0.11848999 0.88151001]\n",
      " [0.11848923 0.88151077]\n",
      " [0.11849182 0.88150818]\n",
      " [0.11849439 0.88150561]\n",
      " [0.11849093 0.88150907]\n",
      " [0.11849029 0.88150971]\n",
      " [0.11848229 0.88151771]\n",
      " [0.11849138 0.88150862]\n",
      " [0.11850171 0.88149829]\n",
      " [0.11849489 0.88150511]\n",
      " [0.11848851 0.88151149]\n",
      " [0.11847149 0.88152851]\n",
      " [0.11847296 0.88152704]\n",
      " [0.11846422 0.88153578]\n",
      " [0.11846756 0.88153244]\n",
      " [0.11847695 0.88152305]\n",
      " [0.11846739 0.88153261]\n",
      " [0.11846758 0.88153242]\n",
      " [0.11847157 0.88152843]\n",
      " [0.11846784 0.88153216]\n",
      " [0.11846529 0.88153471]\n",
      " [0.11845545 0.88154455]\n",
      " [0.11846113 0.88153887]\n",
      " [0.11846082 0.88153918]\n",
      " [0.11846997 0.88153003]\n",
      " [0.11850034 0.88149966]\n",
      " [0.11850048 0.88149952]\n",
      " [0.1184959  0.8815041 ]\n",
      " [0.11849313 0.88150687]\n",
      " [0.11850905 0.88149095]\n",
      " [0.11850088 0.88149912]\n",
      " [0.11849997 0.88150003]\n",
      " [0.11847467 0.88152533]\n",
      " [0.11845022 0.88154978]\n",
      " [0.11845786 0.88154214]\n",
      " [0.11847796 0.88152204]\n",
      " [0.1184681  0.8815319 ]\n",
      " [0.11848073 0.88151927]\n",
      " [0.11848362 0.88151638]\n",
      " [0.11847874 0.88152126]\n",
      " [0.11845941 0.88154059]\n",
      " [0.11846256 0.88153744]\n",
      " [0.11846264 0.88153736]\n",
      " [0.11845859 0.88154141]\n",
      " [0.1184474  0.8815526 ]\n",
      " [0.11844332 0.88155668]\n",
      " [0.11844798 0.88155202]\n",
      " [0.11844887 0.88155113]\n",
      " [0.11851687 0.88148313]\n",
      " [0.11849662 0.88150338]\n",
      " [0.11844665 0.88155335]\n",
      " [0.11844806 0.88155194]\n",
      " [0.11845987 0.88154013]\n",
      " [0.11846153 0.88153847]\n",
      " [0.11846089 0.88153911]\n",
      " [0.11847323 0.88152677]\n",
      " [0.11847038 0.88152962]\n",
      " [0.11847137 0.88152863]\n",
      " [0.11846705 0.88153295]\n",
      " [0.11846861 0.88153139]\n",
      " [0.11846513 0.88153487]\n",
      " [0.11847019 0.88152981]\n",
      " [0.11846919 0.88153081]\n",
      " [0.11845677 0.88154323]\n",
      " [0.118456   0.881544  ]\n",
      " [0.11844568 0.88155432]\n",
      " [0.11846766 0.88153234]\n",
      " [0.11845843 0.88154157]\n",
      " [0.11848451 0.88151549]\n",
      " [0.11846058 0.88153942]\n",
      " [0.11845709 0.88154291]\n",
      " [0.11845233 0.88154767]\n",
      " [0.11846011 0.88153989]\n",
      " [0.11845675 0.88154325]\n",
      " [0.11845491 0.88154509]\n",
      " [0.1184553  0.8815447 ]\n",
      " [0.11845321 0.88154679]\n",
      " [0.11845522 0.88154478]\n",
      " [0.11845462 0.88154538]\n",
      " [0.11845622 0.88154378]\n",
      " [0.11845049 0.88154951]\n",
      " [0.11845675 0.88154325]\n",
      " [0.11845798 0.88154202]\n",
      " [0.11846383 0.88153617]\n",
      " [0.11846654 0.88153346]\n",
      " [0.11846473 0.88153527]\n",
      " [0.11846383 0.88153617]\n",
      " [0.11847003 0.88152997]\n",
      " [0.11846373 0.88153627]\n",
      " [0.11847424 0.88152576]\n",
      " [0.11848058 0.88151942]\n",
      " [0.11848    0.88152   ]\n",
      " [0.11848201 0.88151799]\n",
      " [0.11848298 0.88151702]\n",
      " [0.11848324 0.88151676]\n",
      " [0.11848757 0.88151243]\n",
      " [0.11848769 0.88151231]\n",
      " [0.45090396 0.54909604]\n",
      " [0.35957128 0.64042872]\n",
      " [0.36889769 0.63110231]\n",
      " [0.38143472 0.61856528]\n",
      " [0.45526485 0.54473515]\n",
      " [0.42583551 0.57416449]\n",
      " [0.3274109  0.6725891 ]\n",
      " [0.43179279 0.56820721]\n",
      " [0.38998714 0.61001286]\n",
      " [0.40434185 0.59565815]\n",
      " [0.46417689 0.53582311]\n",
      " [0.37258205 0.62741795]\n",
      " [0.35655974 0.64344026]\n",
      " [0.42257964 0.57742036]\n",
      " [0.32520225 0.67479775]\n",
      " [0.41141119 0.58858881]\n",
      " [0.3315529  0.6684471 ]\n",
      " [0.41478344 0.58521656]\n",
      " [0.45364091 0.54635909]\n",
      " [0.46877577 0.53122423]\n",
      " [0.38675591 0.61324409]\n",
      " [0.45523884 0.54476116]\n",
      " [0.44500951 0.55499049]\n",
      " [0.40022889 0.59977111]\n",
      " [0.36731104 0.63268896]\n",
      " [0.35961422 0.64038578]\n",
      " [0.43656241 0.56343759]\n",
      " [0.43914104 0.56085896]\n",
      " [0.43596196 0.56403804]\n",
      " [0.4199383  0.5800617 ]\n",
      " [0.35792879 0.64207121]\n",
      " [0.41356255 0.58643745]\n",
      " [0.40728005 0.59271995]\n",
      " [0.35667595 0.64332405]\n",
      " [0.45749218 0.54250782]\n",
      " [0.41815905 0.58184095]\n",
      " [0.38047779 0.61952221]\n",
      " [0.32561672 0.67438328]\n",
      " [0.4315086  0.5684914 ]\n",
      " [0.3820366  0.6179634 ]\n",
      " [0.48618662 0.51381338]\n",
      " [0.38084517 0.61915483]\n",
      " [0.47986291 0.52013709]\n",
      " [0.37495832 0.62504168]\n",
      " [0.45614684 0.54385316]\n",
      " [0.39594701 0.60405299]\n",
      " [0.42564889 0.57435111]\n",
      " [0.38855541 0.61144459]\n",
      " [0.41740757 0.58259243]\n",
      " [0.40178521 0.59821479]\n",
      " [0.38510905 0.61489095]\n",
      " [0.39874285 0.60125715]\n",
      " [0.33135589 0.66864411]\n",
      " [0.38717679 0.61282321]\n",
      " [0.3731218  0.6268782 ]\n",
      " [0.43253773 0.56746227]\n",
      " [0.33377373 0.66622627]\n",
      " [0.37069438 0.62930562]\n",
      " [0.41322844 0.58677156]\n",
      " [0.42204089 0.57795911]\n",
      " [0.3482041  0.6517959 ]\n",
      " [0.3956051  0.6043949 ]\n",
      " [0.40707084 0.59292916]\n",
      " [0.3560332  0.6439668 ]\n",
      " [0.42003998 0.57996002]\n",
      " [0.40477574 0.59522426]\n",
      " [0.40008964 0.59991036]\n",
      " [0.42150598 0.57849402]\n",
      " [0.47848887 0.52151113]\n",
      " [0.34076686 0.65923314]\n",
      " [0.34450114 0.65549886]\n",
      " [0.37583137 0.62416863]\n",
      " [0.40844261 0.59155739]\n",
      " [0.41459015 0.58540985]\n",
      " [0.34463466 0.65536534]\n",
      " [0.41525014 0.58474986]\n",
      " [0.41374136 0.58625864]\n",
      " [0.40041241 0.59958759]\n",
      " [0.44425117 0.55574883]\n",
      " [0.3430067  0.6569933 ]\n",
      " [0.4128055  0.5871945 ]\n",
      " [0.30976279 0.69023721]\n",
      " [0.3942572  0.6057428 ]\n",
      " [0.3788596  0.6211404 ]\n",
      " [0.31481592 0.68518408]\n",
      " [0.30361893 0.69638107]\n",
      " [0.33950506 0.66049494]\n",
      " [0.44515724 0.55484276]\n",
      " [0.36665549 0.63334451]\n",
      " [0.36078603 0.63921397]\n",
      " [0.3531888  0.6468112 ]\n",
      " [0.40812091 0.59187909]\n",
      " [0.3867738  0.6132262 ]\n",
      " [0.37320896 0.62679104]\n",
      " [0.37364324 0.62635676]\n",
      " [0.34158794 0.65841206]\n",
      " [0.37767609 0.62232391]\n",
      " [0.394833   0.605167  ]\n",
      " [0.32096027 0.67903973]\n",
      " [0.43773825 0.56226175]\n",
      " [0.35705985 0.64294015]\n",
      " [0.47967017 0.52032983]\n",
      " [0.36304878 0.63695122]]\n",
      "Number of disagreements: 0\n",
      "Number of agreements: 503\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=1, kernel='rbf', gamma=0.4, probability=True, random_state=42)\n",
    "pu_estimator = BaggingPuClassifier(\n",
    "        estimator=svc, n_estimators=50)\n",
    "pu_probability = BaggingPuClassifier(estimator=svc, n_estimators=250)\n",
    "clf = pu_estimator.fit(X, y)\n",
    "#print(pu_estimator.predict(X))\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print(np.array(pu_estimator.predict_proba(X)))\n",
    "print(\n",
    "    \"Number of disagreements: {}\".format(\n",
    "        len(np.where(pu_estimator.predict(X) != np.ones(503))[0])\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Number of agreements: {}\".format(\n",
    "        len(np.where(pu_estimator.predict(X) == np.ones(503))[0])\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      " -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1]\n",
      "384\n",
      "[0.50077792 0.50077792 0.50077792 0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.50065324 0.50065324 0.50065324 0.50067013 0.50067013 0.50067013\n",
      " 0.50067013 0.50067013 0.50067013 0.50067028 0.50067028 0.50067028\n",
      " 0.5006881  0.5006881  0.5006881  0.5006881  0.5006881  0.5006881\n",
      " 0.50070328 0.50070328 0.50070328 0.50070328 0.50070328 0.50070328\n",
      " 0.50070328 0.50070328 0.50070328 0.50072127 0.50072127 0.50072127\n",
      " 0.50072127 0.50072127 0.50072127 0.50072127 0.50072127 0.50072127\n",
      " 0.50072127 0.50072127 0.50072127 0.50072166 0.50072166 0.50072166\n",
      " 0.50072166 0.50072166 0.50072166 0.50072166 0.50072166 0.50072166\n",
      " 0.50072265 0.50072265 0.50072265 0.50072265 0.50072265 0.50072265\n",
      " 0.50073919 0.50073919 0.50073919 0.50073919 0.50073919 0.50073919\n",
      " 0.50073919 0.50073919 0.50073919 0.50073919 0.50073919 0.50073919\n",
      " 0.50073919 0.50073919 0.50073919 0.50073919 0.50073919 0.50073919\n",
      " 0.50073919 0.50073919 0.50073919 0.50073919 0.50073919 0.50073919\n",
      " 0.50074013 0.50074013 0.50065473 0.50067028 0.50000008 0.50075856\n",
      " 0.50074013 0.50074013 0.50074013 0.50074013 0.50074013 0.50074013\n",
      " 0.50074013 0.50074013 0.50074013 0.50074013 0.50074199 0.50074199\n",
      " 0.50074199 0.5        0.50074199 0.50074199 0.50074199 0.50075856\n",
      " 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856\n",
      " 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856\n",
      " 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856\n",
      " 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856\n",
      " 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856\n",
      " 0.50000008 0.5        0.50065473 0.50067028 0.50075856 0.50065473\n",
      " 0.50067028 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856\n",
      " 0.50075952 0.50075952 0.50075952 0.50075952 0.50075952 0.50075952\n",
      " 0.50075952 0.50075952 0.50075952 0.50075952 0.50075952 0.50075952\n",
      " 0.50075952 0.50075952 0.50075952 0.50075952 0.50075952 0.50075952\n",
      " 0.50075952 0.5        0.50065324 0.5006376  0.50075952 0.50075952\n",
      " 0.50075952 0.50075952 0.50075952 0.50077792 0.50077792 0.50077792\n",
      " 0.50065324 0.5006376  0.50077792 0.50077792 0.50077792 0.50077792\n",
      " 0.50077792 0.50077792 0.50077792 0.50077792 0.50077792 0.50077792\n",
      " 0.50077792 0.50077792 0.50077792 0.50065324 0.5006376  0.50077792\n",
      " 0.50077792 0.50077792 0.50077792 0.50077792 0.50077792 0.50077792\n",
      " 0.50077792 0.50077884 0.50077884 0.50077884 0.50077884 0.50077884\n",
      " 0.50077884 0.50077884 0.50077884 0.50077884 0.50077884 0.50077884\n",
      " 0.50077884 0.50067013 0.50067013 0.50067013 0.5006881  0.5006881\n",
      " 0.5006881  0.50070328 0.50070328 0.50070328 0.50070328 0.50070328\n",
      " 0.50070328 0.50072127 0.50072127 0.50072127 0.50072127 0.50072127\n",
      " 0.50072127 0.50072166 0.50072166 0.50072166 0.50072166 0.50072166\n",
      " 0.50072166 0.50072265 0.50072265 0.50072265 0.50073919 0.50073919\n",
      " 0.50073919 0.50073919 0.50073919 0.50073919 0.50073919 0.50073919\n",
      " 0.50073919 0.50073919 0.50073919 0.50073919 0.50074013 0.50074013\n",
      " 0.50074013 0.50074013 0.50074013 0.50074013 0.50074199 0.50074199\n",
      " 0.50074199 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856\n",
      " 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856\n",
      " 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856\n",
      " 0.50075856 0.50075952 0.50075952 0.50075952 0.50075952 0.50075952\n",
      " 0.50075952 0.50075952 0.50075952 0.50075952 0.50075952 0.50075952\n",
      " 0.50075952 0.50077792 0.50077792 0.50077792 0.50077792 0.50077792\n",
      " 0.50077792 0.50077792 0.50077792 0.50077792 0.50077792 0.50077792\n",
      " 0.50077792 0.50077884 0.50077884 0.50077884 0.50077884 0.50077884\n",
      " 0.50077884 0.50070328 0.50070328 0.50070328 0.5        0.5\n",
      " 0.50072127 0.50072127 0.50072127 0.50072166 0.50072166 0.50072166\n",
      " 0.50072265 0.50072265 0.50072265 0.50073919 0.50073919 0.50073919\n",
      " 0.50073919 0.50073919 0.50073919 0.50074013 0.50074013 0.50074013\n",
      " 0.50074199 0.50074199 0.50074199 0.50075856 0.50075856 0.50075856\n",
      " 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856\n",
      " 0.50075952 0.50075952 0.50075952 0.50075952 0.50075952 0.50075952\n",
      " 0.50077792 0.50077792 0.50077792 0.50077792 0.50077792 0.50077792\n",
      " 0.50077884 0.50077884 0.50077884 0.50072127 0.50072127 0.50072127\n",
      " 0.50073919 0.50073919 0.50073919 0.50074013 0.50074013 0.50074013\n",
      " 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856 0.50075856\n",
      " 0.50075952 0.50075952 0.50075952 0.50077792 0.50077792 0.50077792\n",
      " 0.50077884 0.50077884 0.50077884 0.50075856 0.5        0.5\n",
      " 0.5        0.50000008 0.50000008 0.50000015 0.50000015 0.50073919\n",
      " 0.50073919 0.50073919 0.50075952 0.50075952 0.50075952]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "clf = OneClassSVM(kernel=\"rbf\",gamma=3).fit(X)\n",
    "print(clf.predict(X))\n",
    "print(len(np.where(clf.predict(X) == np.ones(503))[0]))\n",
    "print(clf.score_samples(X))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
